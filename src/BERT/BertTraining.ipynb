{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m deeppavlov install ner_ontonotes_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deeppavlov import configs, build_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-07 07:56:42.391 INFO in 'deeppavlov.download'['download'] at line 132: Skipped http://files.deeppavlov.ai/deeppavlov_data/bert/cased_L-12_H-768_A-12.zip download because of matching hashes\n",
      "2020-07-07 07:56:44.767 INFO in 'deeppavlov.download'['download'] at line 132: Skipped http://files.deeppavlov.ai/deeppavlov_data/ner_ontonotes_bert_v1.tar.gz download because of matching hashes\n",
      "[nltk_data] Downloading package punkt to /home/itm3f/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/itm3f/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package perluniprops to\n",
      "[nltk_data]     /home/itm3f/nltk_data...\n",
      "[nltk_data]   Package perluniprops is already up-to-date!\n",
      "[nltk_data] Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]     /home/itm3f/nltk_data...\n",
      "[nltk_data]   Package nonbreaking_prefixes is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/itm3f/.conda/envs/BERT-NER/lib/python3.7/site-packages/bert_dp/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-07 07:56:59.921 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /sfs/qumulo/qhome/itm3f/.deeppavlov/models/ner_ontonotes_bert/tag.dict]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/itm3f/.local/lib/python3.7/site-packages/deeppavlov/core/models/tf_model.py:37: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/itm3f/.local/lib/python3.7/site-packages/deeppavlov/core/models/tf_model.py:222: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/itm3f/.local/lib/python3.7/site-packages/deeppavlov/core/models/tf_model.py:222: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/itm3f/.local/lib/python3.7/site-packages/deeppavlov/core/models/tf_model.py:193: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/itm3f/.local/lib/python3.7/site-packages/deeppavlov/models/bert/bert_sequence_tagger.py:236: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/itm3f/.local/lib/python3.7/site-packages/deeppavlov/models/bert/bert_sequence_tagger.py:314: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/itm3f/.conda/envs/BERT-NER/lib/python3.7/site-packages/bert_dp/modeling.py:178: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/itm3f/.conda/envs/BERT-NER/lib/python3.7/site-packages/bert_dp/modeling.py:418: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/itm3f/.conda/envs/BERT-NER/lib/python3.7/site-packages/bert_dp/modeling.py:499: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.\n",
      "\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /home/itm3f/.conda/envs/BERT-NER/lib/python3.7/site-packages/bert_dp/modeling.py:366: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/itm3f/.conda/envs/BERT-NER/lib/python3.7/site-packages/bert_dp/modeling.py:680: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "WARNING:tensorflow:From /home/itm3f/.conda/envs/BERT-NER/lib/python3.7/site-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From /home/itm3f/.conda/envs/BERT-NER/lib/python3.7/site-packages/bert_dp/modeling.py:283: The name tf.erf is deprecated. Please use tf.math.erf instead.\n",
      "\n",
      "WARNING:tensorflow:Variable *= will be deprecated. Use `var.assign(var * other)` if you want assignment to the variable value or `x = x * y` if you want a new python Tensor object.\n",
      "WARNING:tensorflow:From /home/itm3f/.local/lib/python3.7/site-packages/deeppavlov/models/bert/bert_sequence_tagger.py:75: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/itm3f/.conda/envs/BERT-NER/lib/python3.7/site-packages/tensorflow_core/contrib/crf/python/ops/crf.py:213: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /home/itm3f/.local/lib/python3.7/site-packages/deeppavlov/core/models/tf_model.py:234: The name tf.train.AdadeltaOptimizer is deprecated. Please use tf.compat.v1.train.AdadeltaOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/itm3f/.local/lib/python3.7/site-packages/deeppavlov/core/models/tf_model.py:131: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/itm3f/.local/lib/python3.7/site-packages/deeppavlov/core/models/tf_model.py:131: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/itm3f/.local/lib/python3.7/site-packages/deeppavlov/core/models/tf_model.py:94: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/itm3f/.conda/envs/BERT-NER/lib/python3.7/site-packages/tensorflow_core/python/training/moving_averages.py:433: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "WARNING:tensorflow:From /home/itm3f/.local/lib/python3.7/site-packages/deeppavlov/models/bert/bert_sequence_tagger.py:671: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/itm3f/.local/lib/python3.7/site-packages/deeppavlov/models/bert/bert_sequence_tagger.py:244: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/itm3f/.local/lib/python3.7/site-packages/deeppavlov/models/bert/bert_sequence_tagger.py:249: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-07 07:57:21.399 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /sfs/qumulo/qhome/itm3f/.deeppavlov/models/ner_ontonotes_bert/model]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/itm3f/.local/lib/python3.7/site-packages/deeppavlov/core/models/tf_model.py:54: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from /sfs/qumulo/qhome/itm3f/.deeppavlov/models/ner_ontonotes_bert/model\n"
     ]
    }
   ],
   "source": [
    "ner_model = build_model(configs.ner.ner_ontonotes_bert, download=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['Bob', 'Ross', 'lived', 'in', 'Florida']],\n",
       " [['B-PERSON', 'I-PERSON', 'O', 'O', 'B-GPE']]]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#O Object\n",
    "ner_model(['Bob Ross lived in Florida'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['Harry', 'Potter', 'is', 'based', 'in', 'London']],\n",
       " [['B-PERSON', 'I-PERSON', 'O', 'O', 'O', 'B-GPE']]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_model([\"Harry Potter is based in London\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('../../data/original/DNA_DATA_FULL.gz', compression='gzip') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_dict = pd.read_csv(\"../../data/original/companies.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Looking at just one article</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = df.iloc[10:20][['company_codes', 'body']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_codes</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>,actsws,actsws,jjprd,jjprd,jonjon,jonjon,usfda...</td>\n",
       "      <td>The 10 drugs, which include therapies for canc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>,tkdci,tkdci,tkdci,</td>\n",
       "      <td>The acquisition will also provide long-term st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>,hltacq,seexc,hltacq,hltacq,nasdaq,nasdaq,seex...</td>\n",
       "      <td>The full text of this SEC filing can be retrie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>,abvbba,abvbba,boehig,usfda,abvbba,</td>\n",
       "      <td>AbbVie will present late-breaking studies on t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>,onclbt,usfda,onclbt,onclbt,usfda,usfda,stveii,</td>\n",
       "      <td>Based on the April data from the company’s ope...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>,usfda,usfda,</td>\n",
       "      <td>This program is an important part of a product...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>,aetla,aetla,blucks,cdcfui,congen,congen,dnatc...</td>\n",
       "      <td>CMS\\n\\nCMS in October released a final rule to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>,maym,medinc,vsuals,emryuv,maym,maym,medinc,me...</td>\n",
       "      <td>‘We’re excited about this important milestone ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>,nqdeps,nqdeps,nqdeps,ntnct,rsuvmc,twnit,</td>\n",
       "      <td>\"Like many women who have lived through an ova...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>,amaoas,clfitg,iaolsi,illmna,illmna,nasdaq,nas...</td>\n",
       "      <td>SECTION 1 BIOGRAPHY FRANCES ARNOLD, DIRECTOR\\n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        company_codes  \\\n",
       "10  ,actsws,actsws,jjprd,jjprd,jonjon,jonjon,usfda...   \n",
       "11                                ,tkdci,tkdci,tkdci,   \n",
       "12  ,hltacq,seexc,hltacq,hltacq,nasdaq,nasdaq,seex...   \n",
       "13                ,abvbba,abvbba,boehig,usfda,abvbba,   \n",
       "14    ,onclbt,usfda,onclbt,onclbt,usfda,usfda,stveii,   \n",
       "15                                      ,usfda,usfda,   \n",
       "16  ,aetla,aetla,blucks,cdcfui,congen,congen,dnatc...   \n",
       "17  ,maym,medinc,vsuals,emryuv,maym,maym,medinc,me...   \n",
       "18          ,nqdeps,nqdeps,nqdeps,ntnct,rsuvmc,twnit,   \n",
       "19  ,amaoas,clfitg,iaolsi,illmna,illmna,nasdaq,nas...   \n",
       "\n",
       "                                                 body  \n",
       "10  The 10 drugs, which include therapies for canc...  \n",
       "11  The acquisition will also provide long-term st...  \n",
       "12  The full text of this SEC filing can be retrie...  \n",
       "13  AbbVie will present late-breaking studies on t...  \n",
       "14  Based on the April data from the company’s ope...  \n",
       "15  This program is an important part of a product...  \n",
       "16  CMS\\n\\nCMS in October released a final rule to...  \n",
       "17  ‘We’re excited about this important milestone ...  \n",
       "18  \"Like many women who have lived through an ova...  \n",
       "19  SECTION 1 BIOGRAPHY FRANCES ARNOLD, DIRECTOR\\n...  "
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['Dr',\n",
       "   '.',\n",
       "   'Curiel',\n",
       "   'is',\n",
       "   'the',\n",
       "   'leader',\n",
       "   'for',\n",
       "   'TumAdoR',\n",
       "   'Project',\n",
       "   '6',\n",
       "   ',',\n",
       "   'funded',\n",
       "   'at',\n",
       "   '$',\n",
       "   '800',\n",
       "   ',',\n",
       "   '000',\n",
       "   '.',\n",
       "   'His',\n",
       "   \"team's\",\n",
       "   'mission',\n",
       "   'is',\n",
       "   'to',\n",
       "   'develop',\n",
       "   'mice',\n",
       "   'with',\n",
       "   'human',\n",
       "   'immune',\n",
       "   'systems',\n",
       "   'and',\n",
       "   'other',\n",
       "   'models',\n",
       "   'and',\n",
       "   'additional',\n",
       "   'tests',\n",
       "   'to',\n",
       "   'be',\n",
       "   'sure',\n",
       "   'that',\n",
       "   'the',\n",
       "   'developed',\n",
       "   'antibody',\n",
       "   'can',\n",
       "   'block',\n",
       "   'the',\n",
       "   'metabolic',\n",
       "   'pathway',\n",
       "   ',',\n",
       "   'and',\n",
       "   'to',\n",
       "   'assess',\n",
       "   'what',\n",
       "   'the',\n",
       "   'immune',\n",
       "   'consequences',\n",
       "   'will',\n",
       "   'be',\n",
       "   'in',\n",
       "   'humans',\n",
       "   '.',\n",
       "   '\\n',\n",
       "   '\\n',\n",
       "   'The',\n",
       "   'TumAdoR',\n",
       "   'project',\n",
       "   'weaves',\n",
       "   'together',\n",
       "   'the',\n",
       "   'skills',\n",
       "   'of',\n",
       "   'seven',\n",
       "   'different',\n",
       "   'teams',\n",
       "   'from',\n",
       "   'Germany',\n",
       "   ',',\n",
       "   'Switzerland',\n",
       "   ',',\n",
       "   'France',\n",
       "   ',',\n",
       "   'Finland',\n",
       "   'and',\n",
       "   'the',\n",
       "   'UT',\n",
       "   'Health',\n",
       "   'Science',\n",
       "   'Center',\n",
       "   'to',\n",
       "   'attack',\n",
       "   'the',\n",
       "   'problem',\n",
       "   'from',\n",
       "   'multiple',\n",
       "   'perspectives',\n",
       "   'such',\n",
       "   'as',\n",
       "   'immunology',\n",
       "   ',',\n",
       "   'drug',\n",
       "   'development',\n",
       "   ',',\n",
       "   'and',\n",
       "   'clinical',\n",
       "   'trial',\n",
       "   'design',\n",
       "   'and',\n",
       "   'management',\n",
       "   '.',\n",
       "   '\\n',\n",
       "   '\\n',\n",
       "   'Its',\n",
       "   'target',\n",
       "   'is',\n",
       "   'CD73',\n",
       "   ',',\n",
       "   'an',\n",
       "   'enzyme',\n",
       "   'that',\n",
       "   'is',\n",
       "   'overexpressed',\n",
       "   'in',\n",
       "   'many',\n",
       "   'different',\n",
       "   'kinds',\n",
       "   'of',\n",
       "   'cancer',\n",
       "   '.',\n",
       "   'CD73',\n",
       "   'helps',\n",
       "   'produce',\n",
       "   'excess',\n",
       "   'amounts',\n",
       "   'of',\n",
       "   'adenosine',\n",
       "   ',',\n",
       "   'which',\n",
       "   'is',\n",
       "   'needed',\n",
       "   'to',\n",
       "   'produce',\n",
       "   'energy',\n",
       "   'in',\n",
       "   'cells',\n",
       "   ',',\n",
       "   'but',\n",
       "   'also',\n",
       "   'can',\n",
       "   'suppress',\n",
       "   'the',\n",
       "   'immune',\n",
       "   'system',\n",
       "   'and',\n",
       "   'allow',\n",
       "   'the',\n",
       "   'tumor',\n",
       "   'cells',\n",
       "   'to',\n",
       "   'reproduce',\n",
       "   '.',\n",
       "   '\\n',\n",
       "   '\\n',\n",
       "   'Adenosine',\n",
       "   'is',\n",
       "   'not',\n",
       "   'normally',\n",
       "   'immune',\n",
       "   '-',\n",
       "   'suppressive',\n",
       "   ',',\n",
       "   '\"',\n",
       "   'but',\n",
       "   'it',\n",
       "   'is',\n",
       "   'when',\n",
       "   'you',\n",
       "   'generate',\n",
       "   'lots',\n",
       "   'of',\n",
       "   'it',\n",
       "   ',',\n",
       "   'as',\n",
       "   'tumors',\n",
       "   'do',\n",
       "   '.',\n",
       "   'Tumors',\n",
       "   'do',\n",
       "   'everything',\n",
       "   'in',\n",
       "   'a',\n",
       "   'crazy',\n",
       "   'way',\n",
       "   ',',\n",
       "   '\"',\n",
       "   'Dr',\n",
       "   '.',\n",
       "   'Curiel',\n",
       "   'said',\n",
       "   '.',\n",
       "   '\\n',\n",
       "   '\\n',\n",
       "   'Antibody',\n",
       "   'therapy',\n",
       "   'is',\n",
       "   'already',\n",
       "   'a',\n",
       "   'proven',\n",
       "   'success',\n",
       "   '-',\n",
       "   'one',\n",
       "   'example',\n",
       "   'is',\n",
       "   'Herceptin',\n",
       "   ',',\n",
       "   'an',\n",
       "   'antibody',\n",
       "   'drug',\n",
       "   'used',\n",
       "   'to',\n",
       "   'treat',\n",
       "   'breast',\n",
       "   'cancer',\n",
       "   '-',\n",
       "   'but',\n",
       "   'the',\n",
       "   'promising',\n",
       "   'thing',\n",
       "   'about',\n",
       "   'this',\n",
       "   'project',\n",
       "   'is',\n",
       "   'that',\n",
       "   'the',\n",
       "   'drug',\n",
       "   'may',\n",
       "   'well',\n",
       "   'work',\n",
       "   'against',\n",
       "   'several',\n",
       "   'types',\n",
       "   'of',\n",
       "   'cancer',\n",
       "   '.',\n",
       "   '\\n',\n",
       "   '\\n',\n",
       "   'Keywords',\n",
       "   'for',\n",
       "   'this',\n",
       "   'news',\n",
       "   'article',\n",
       "   'include',\n",
       "   ':',\n",
       "   'Antibodies',\n",
       "   ',',\n",
       "   'Cancer',\n",
       "   ',',\n",
       "   'Therapy',\n",
       "   ',',\n",
       "   'Oncology',\n",
       "   ',',\n",
       "   'Immunology',\n",
       "   ',',\n",
       "   'Blood',\n",
       "   'Proteins',\n",
       "   ',',\n",
       "   'Immunoglobulins',\n",
       "   ',',\n",
       "   'Hemic',\n",
       "   'and',\n",
       "   'Immune',\n",
       "   'Systems',\n",
       "   ',',\n",
       "   'Clinical',\n",
       "   'Trials',\n",
       "   'and',\n",
       "   'Studies',\n",
       "   ',',\n",
       "   'University',\n",
       "   'of',\n",
       "   'Texas',\n",
       "   'Health',\n",
       "   'Science',\n",
       "   'Center',\n",
       "   'at',\n",
       "   'San',\n",
       "   'Antonio',\n",
       "   '.',\n",
       "   '\\n',\n",
       "   '\\n',\n",
       "   'Our',\n",
       "   'reports',\n",
       "   'deliver',\n",
       "   'fact',\n",
       "   '-',\n",
       "   'based',\n",
       "   'news',\n",
       "   'of',\n",
       "   'research',\n",
       "   'and',\n",
       "   'discoveries',\n",
       "   'from',\n",
       "   'around',\n",
       "   'the',\n",
       "   'world',\n",
       "   '.',\n",
       "   'Copyright',\n",
       "   '2014',\n",
       "   ',',\n",
       "   'NewsRx',\n",
       "   'LLC']],\n",
       " [['O',\n",
       "   'O',\n",
       "   'B-PERSON',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'B-ORG',\n",
       "   'I-ORG',\n",
       "   'I-ORG',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'B-MONEY',\n",
       "   'I-MONEY',\n",
       "   'I-MONEY',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'B-ORG',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'B-CARDINAL',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'B-GPE',\n",
       "   'O',\n",
       "   'B-GPE',\n",
       "   'O',\n",
       "   'B-GPE',\n",
       "   'O',\n",
       "   'B-GPE',\n",
       "   'O',\n",
       "   'B-ORG',\n",
       "   'I-ORG',\n",
       "   'I-ORG',\n",
       "   'I-ORG',\n",
       "   'I-ORG',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'B-PERSON',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'B-CARDINAL',\n",
       "   'O',\n",
       "   'O',\n",
       "   'B-PRODUCT',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'B-ORG',\n",
       "   'I-ORG',\n",
       "   'I-ORG',\n",
       "   'I-ORG',\n",
       "   'I-ORG',\n",
       "   'I-ORG',\n",
       "   'O',\n",
       "   'B-GPE',\n",
       "   'I-GPE',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'B-DATE',\n",
       "   'O',\n",
       "   'B-ORG',\n",
       "   'I-ORG']]]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_model([df.iloc[2]['body']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-BERT-NER]",
   "language": "python",
   "name": "conda-env-.conda-BERT-NER-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
