{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Profiling DNA Data Report \n",
    "\n",
    "## Outline\n",
    "* Inventory of Dataset \n",
    "    * Overview of Pandas Profiling Results \n",
    "    * Validity Check of Select Variables\n",
    "    * Table for Completeness, Uniqueness and Duplicates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import gzip\n",
    "from collections import Counter \n",
    "from datetime import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-f5d3c1cc2461>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/original/DNA_DATA_FULL.gz'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gzip'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36mread_json\u001b[0;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, numpy, precise_float, date_unit, encoding, lines, chunksize, compression)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0mlines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m         \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m         \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m     )\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filepath_or_buffer, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, numpy, precise_float, date_unit, encoding, lines, chunksize, compression)\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data_from_filepath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_preprocess_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_preprocess_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36m_preprocess_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    660\u001b[0m         \"\"\"\n\u001b[1;32m    661\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"read\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 662\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    663\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"read\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStringIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/apps/software/standard/compiler/gcc/7.1.0/jupyter_conda/2019.10-py3.7/lib/python3.7/gzip.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    274\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0merrno\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEBADF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"read() on write-only GzipFile object\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df = pd.read_json('../data/original/DNA_DATA_FULL.gz', compression='gzip') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><b>Data Profiling</b></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><b>Validity Check for Company-Related Columns</b></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><b>Getting only the columns that deal with the company codes</b></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Looking only at the company columns\n",
    "#companies = df[['company_codes', 'company_codes_occur', 'company_codes_about', 'company_codes_lineage', 'company_codes_association', 'company_codes_relevance']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#There are no values in this column so it will not be part of the validating process\n",
    "#print(companies['company_codes_association'].value_counts())\n",
    "companies = df[['company_codes', 'company_codes_occur', 'company_codes_about', 'company_codes_lineage', 'company_codes_relevance']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><b>Loading in company code dictionary</b></h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uploading the data dictionary into a dataframe\n",
    "code_dict = pd.read_csv(\"../data/original/companies.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><b>Creating a profile table for validity</b></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For validating, I will be taking each unique company code in all of the columns and checking to see if each one is in the company codes dictionary\n",
    "#The dataframe below will keep track of the % of valid company codes\n",
    "#profile = pd.DataFrame({\"Validity\": np.zeros(len(companies.columns))}).set_index(companies.columns)\n",
    "validity_col = df[['company_codes', 'company_codes_occur', 'company_codes_about', 'company_codes_lineage', 'company_codes_relevance', 'body', 'publication_datetime']]\n",
    "profile = pd.DataFrame({\"Validity\": np.zeros(7)}).set_index(validity_col.columns)\n",
    "\n",
    "#profile\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><b>Creating validity function</b></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here is the validity function I will be using\n",
    "#returns the sum of True and divides by the length of the unique list\n",
    "def checkValidity(ls, col = code_dict.code.tolist()):\n",
    "    return sum([code in col for code in ls]) / len(ls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><b>Getting unique codes for each column</b></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TPMJTY', 'ITLCOR', 'NYRKMD', 'FRJNS', 'CLYCAP', 'GROUP', 'IPLNN', 'SMLBSL', 'PKDEAG', 'HFNTIR']\n",
      "There are 73688 unique company codes\n"
     ]
    }
   ],
   "source": [
    "#Getting the unique company codes\n",
    "unique_company_codes = set()\n",
    "for value in companies['company_codes']:\n",
    "    unique_company_codes.update(value.split(\",\"))\n",
    "\n",
    "#Convert set back to list\n",
    "unique_company_codes = list(unique_company_codes)\n",
    "unique_company_codes = unique_company_codes[1:] #The first element was '', so I didn't include it in the final list\n",
    "unique_company_codes = [word.upper() for word in unique_company_codes]\n",
    "print(unique_company_codes[0:10])\n",
    "print(\"There are {} unique company codes\".format(len(unique_company_codes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TPMJTY', 'ITLCOR', 'NYRKMD', 'FRJNS', 'CLYCAP', 'GROUP', 'IPLNN', 'SMLBSL', 'PKDEAG', 'HFNTIR']\n",
      "There are 62381 unique companies in unique_companies_occur\n"
     ]
    }
   ],
   "source": [
    "#Unique companies from company_codes_occur\n",
    "unique_companies_occur = set()\n",
    "\n",
    "for value in df['company_codes_occur']:\n",
    "    unique_companies_occur.update(value.split(\",\"))\n",
    "\n",
    "unique_companies_occur = list(unique_companies_occur)\n",
    "unique_companies_occur = unique_companies_occur[1:]\n",
    "unique_companies_occur = [word.upper() for word in unique_companies_occur]\n",
    "print(unique_companies_occur[0:10])\n",
    "print(\"There are {} unique companies in unique_companies_occur\".format(len(unique_companies_occur))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TPMJTY', 'ITLCOR', 'NYRKMD', 'FRJNS', 'CLYCAP', 'GROUP', 'PKDEAG', 'HUNA', 'KPMG', 'VMNTVE']\n",
      "There are 30780 unique companies in unique_companies_about\n"
     ]
    }
   ],
   "source": [
    "#unique companies from company_codes_about\n",
    "unique_companies_about = set()\n",
    "\n",
    "for value in df['company_codes_about']:\n",
    "    unique_companies_about.update(value.split(\",\"))\n",
    "\n",
    "unique_companies_about = list(unique_companies_about)\n",
    "unique_companies_about = unique_companies_about[1:]\n",
    "unique_companies_about = [word.upper() for word in unique_companies_about]\n",
    "print(unique_companies_about[0:10])\n",
    "print(\"There are {} unique companies in unique_companies_about\".format(len(unique_companies_about)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TPMJTY', 'ITLCOR', 'NYRKMD', 'FRJNS', 'CLYCAP', 'GROUP', 'IPLNN', 'SMLBSL', 'HFNTIR', 'PKDEAG']\n",
      "There are 66451 unique companies in unique_companies_relevance\n"
     ]
    }
   ],
   "source": [
    "#unique companies from company_codes_relevance\n",
    "unique_companies_relevance = set()\n",
    "\n",
    "for value in df['company_codes_relevance']:\n",
    "    unique_companies_relevance.update(value.split(\",\"))\n",
    "\n",
    "unique_companies_relevance = list(unique_companies_relevance)\n",
    "unique_companies_relevance = unique_companies_relevance[1:]\n",
    "unique_companies_relevance = [word.upper() for word in unique_companies_relevance]\n",
    "print(unique_companies_relevance[0:10])\n",
    "print(\"There are {} unique companies in unique_companies_relevance\".format(len(unique_companies_relevance)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ZYMEHA', 'CEVEGL', 'BORNGI', 'CMAJLI', 'PKDEAG', 'TIGEN', 'WALJ', 'LUGQKV', 'CELGEN', 'PEPRT']\n",
      "There are 3467 unique companies in unique_companies_lineage\n"
     ]
    }
   ],
   "source": [
    "#unique companies from company_codes_lineage\n",
    "unique_companies_lineage = set()\n",
    "\n",
    "for value in df['company_codes_lineage']:\n",
    "    unique_companies_lineage.update(value.split(\",\"))\n",
    "\n",
    "unique_companies_lineage = list(unique_companies_lineage)\n",
    "unique_companies_lineage = unique_companies_lineage[1:]\n",
    "\n",
    "#Convert to uppercase bc data dictionary has all codes in upper case\n",
    "unique_companies_lineage = [word.upper() for word in unique_companies_lineage]\n",
    "print(unique_companies_lineage[0:10])\n",
    "print(\"There are {} unique companies in unique_companies_lineage\".format(len(unique_companies_lineage)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><b>Checking validity for each column and applying the result to the profile table</b></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile.iloc[0] = 86.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile.iloc[1] = checkValidity(unique_companies_occur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile.iloc[2] = checkValidity(unique_companies_about)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(checkValidity(unique_companies_lineage))\n",
    "profile.iloc[3] = checkValidity(unique_companies_lineage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile.iloc[4] = checkValidity(unique_companies_relevance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><b>Company Code Validity Results</b></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Validity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>company_codes</th>\n",
       "      <td>86.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>company_codes_occur</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>company_codes_about</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>company_codes_lineage</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>company_codes_relevance</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>body</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>publication_datetime</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Validity\n",
       "company_codes                86.9\n",
       "company_codes_occur           0.0\n",
       "company_codes_about           0.0\n",
       "company_codes_lineage         0.0\n",
       "company_codes_relevance       0.0\n",
       "body                          0.0\n",
       "publication_datetime          0.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><b>Getting the invalid company codes</b></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting all the invalid company codes\n",
    "invalid_company_codes = np.array([])\n",
    "for co in unique_company_codes:\n",
    "    if co not in code_dict.code.tolist():\n",
    "        invalid_company_codes = np.append(invalid_company_codes, co)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 9683 invalid companies\n"
     ]
    }
   ],
   "source": [
    "print(\"There are {} invalid companies\".format(len(invalid_company_codes)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><b>Added a csv to the working folder that has all the invalid company codes from the company codes column</b></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#All the codes that are in the dataset but not in the data dictionary\n",
    "invalid_df = pd.DataFrame()\n",
    "invalid_df['code'] = invalid_company_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_df.to_csv(\"../data/working/invalidcompanycodes.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><b>Double checking to make sure that no codes in the invalid_company_codes list are valid (Should get 0% valid)</b></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(checkValidity(invalid_company_codes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><b>Listing some of the invalid codes (aka codes in the dataset but not in the dictionary)</b></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['KUKXBV', 'AMSFFRA', 'LUNFCI', 'GANCMM', 'INSTLC', 'BZHTAKX',\n",
       "       'BFLMII', 'LVDTIN', 'DALNGEZ', 'CUCMAL', 'CRPZJHJ', 'AHMUCPH',\n",
       "       'CADRHL', 'RHALUM', 'AWTRA', 'AKVYHCU', 'ORTHVT', 'KLINGC',\n",
       "       'KLICO', 'REESSQ', 'WELHGL', 'MOCENU', 'APPUDYG', 'COJZCJA',\n",
       "       'CSUFFR', 'OCOUHD', 'GNTXUI', 'NOVPLL', 'NIKOUI', 'PITTOI'],\n",
       "      dtype='<U32')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invalid_company_codes[0:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-7e3cfc602257>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Row'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df['Row'] = np.arange(0, len(df)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><b>Filtering through the dataset and keeping track of rows with at least one invalid company in them</b></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_row = []\n",
    "for row in df.itertuples():\n",
    "    for code in row.company_codes.split(\",\"):\n",
    "        if code.upper() in invalid_company_codes:\n",
    "            invalid_row.append(row.Row)\n",
    "\n",
    "invalid_row = set(invalid_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_row = list(invalid_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_row.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 161321 rows with at least one invalid company code in the company_codes column, which is about 8.303295922752856% of the entire dataset\n"
     ]
    }
   ],
   "source": [
    "print(\"There are {} rows with at least one invalid company code in the company_codes column, which is about {}% of the entire dataset\".format(len(invalid_row),  len(invalid_row) / len(df) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17, 19, 35, 38, 59, 67, 68, 70, 72, 94, 108, 121, 134, 139, 146, 159, 161, 164, 184, 201, 203, 211, 251, 255, 263, 277, 283, 316, 322, 331, 341, 347, 379, 390, 412, 428, 434, 439, 458, 460, 462, 464, 509, 519, 532, 538, 547, 560, 577, 612, 613, 629, 639, 645, 653, 677, 695, 703, 714, 735, 746, 761, 770, 780, 831, 832, 872, 878, 884, 890, 906, 921, 923, 939, 945, 951, 954, 956, 964, 993, 1015, 1046, 1052, 1056, 1062, 1067, 1071, 1072, 1075, 1077, 1078, 1082, 1087, 1129, 1158, 1159, 1163, 1172, 1188, 1212]\n"
     ]
    }
   ],
   "source": [
    "#First 100 invalid rows\n",
    "print(invalid_row[0:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Validity check for Body** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are interested in ensuring the data set only includes written articles and excludes quick news on a given company. Furthermore, given the capacity of the machine learning algorithms we inted to use on this text, we have decide to limit the amount of words in the article to 10,000. This sets the criteria for a valid entry of body to be more than 100 words, but less than 10,000. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping all the columns except for body\n",
    "text = df['body'].fillna(\"Nothing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gathering the word count for each row\n",
    "word_count_all = []\n",
    "\n",
    "for words in text:\n",
    "   word_count_all.append(int(len(words.split())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "validity_body_all = []\n",
    "\n",
    "#creates a loop where any text with less than 100 words or more than 10,000 words is considered an invalid \n",
    "#data point. The reason for these numbers are that anything less than 100 words does not fit our definition of\n",
    "#an article and anything longer than 10,000 words is too long for us to check?\n",
    "for number in word_count_all:\n",
    "    if number < 100:\n",
    "        validity_body_all.append(0)\n",
    "        \n",
    "    elif number > 10000:\n",
    "        validity_body_all.append(0)\n",
    "        \n",
    "    else:\n",
    "        validity_body_all.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78%, or 1520983 of the data in body are valid\n"
     ]
    }
   ],
   "source": [
    "#Validity percentage\n",
    "all_total_valid = sum(validity_body_all)\n",
    "\n",
    "print('{}%, or'.format(round(all_total_valid/len(validity_body_all)*100)), all_total_valid, 'of the data in body are valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates a data frame with all the valid body points along with the body info\n",
    "valid_df = pd.DataFrame()\n",
    "valid_df['body'] = df['body']\n",
    "valid_df['word_count'] = word_count_all\n",
    "valid_df['validity'] = validity_body_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(421872, 3)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check which of these rows specifically are invalid \n",
    "invalid_body = valid_df['validity'] == 0\n",
    "invalid_body_text = valid_df[invalid_body]\n",
    "invalid_body_text.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Validity check for Publication Date**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = df['publication_datetime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transforms the date from timestamp to a string \n",
    "dates_all_iso = []\n",
    "\n",
    "for date in dates:\n",
    "     dates_all_iso.append(dt.fromtimestamp(date/1000.0).strftime('%Y'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_date_all_df = pd.DataFrame()\n",
    "valid_date_all_df['Date'] = dates_all_iso\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#years should be 2010 and onwards. We realllly expect to see 2013-2018 though\n",
    "validity_date_all = list((valid_date_all_df['Date'] > '2009'))\n",
    "\n",
    "valid_date_all_df['Validity'] = validity_date_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%, or 1942855 of the data in modification datetime are valid\n"
     ]
    }
   ],
   "source": [
    "print('{}%, or'.format(round(sum(valid_date_all_df['Validity'] == True) / len(valid_date_all_df['Validity']) * 100)), '{} of the data in modification datetime are valid'.format(sum(valid_date_all_df['Validity'] == True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding publication date and body to validity table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Validity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>company_codes</th>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>company_codes_occur</th>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>company_codes_about</th>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>company_codes_lineage</th>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>company_codes_relevance</th>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>body</th>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>publication_datetime</th>\n",
       "      <td>0.78286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Validity\n",
       "company_codes             0.00000\n",
       "company_codes_occur       0.00000\n",
       "company_codes_about       0.00000\n",
       "company_codes_lineage     0.00000\n",
       "company_codes_relevance   0.00000\n",
       "body                      1.00000\n",
       "publication_datetime      0.78286"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#publication is actually 100% valid, and body is .78286% valid\n",
    "profile.iloc[5] = sum(valid_date_all_df['Validity'] == True) / len(valid_date_all_df['Validity'])\n",
    "profile.iloc[6] = all_total_valid/len(validity_body_all)\n",
    "\n",
    "profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><b>Completeness, Uniqueness, and Duplicates</b></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create profiling dataframe\n",
    "prof = pd.DataFrame({\"Completeness\": np.zeros(len(df.columns)).astype(int), \"Uniqueness\": np.zeros(len(df.columns)).astype(int),\"Duplicates\": np.zeros(len(df.columns)).astype(int)}).set_index(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><b>Functions for Completeness, Uniqueness, and Duplicates</b><h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findCompleteness(col):\n",
    "    return sum(~col.isnull()) / len(col)\n",
    "\n",
    "#NaN not counted as unique\n",
    "def isUnique(col):\n",
    "    return (len(col.unique()) - sum(col.isnull().unique())) / (len(col) - sum(col.isnull()))\n",
    "\n",
    "def checkDuplicates(col):\n",
    "    return sum(col.duplicated()) / len(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><b>Applying each function</b></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying completeness to a df\n",
    "prof['Completeness'] = df.apply(findCompleteness)\n",
    "\n",
    "#Applying the unique function\n",
    "prof['Uniqueness'] = df.apply(isUnique)\n",
    "\n",
    "#Applying the duplicate function\n",
    "prof['Duplicates'] = df.apply(checkDuplicates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><b>Profile</b></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Completeness</th>\n",
       "      <th>Uniqueness</th>\n",
       "      <th>Duplicates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>copyright</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.014934e-03</td>\n",
       "      <td>0.992985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject_codes</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.732466e-01</td>\n",
       "      <td>0.826753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>art</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.040685e-02</td>\n",
       "      <td>0.989593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>modification_datetime</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.468182e-01</td>\n",
       "      <td>0.353182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>body</th>\n",
       "      <td>0.975772</td>\n",
       "      <td>8.207384e-01</td>\n",
       "      <td>0.199146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>company_codes_occur</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.813707e-01</td>\n",
       "      <td>0.818629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>company_codes_about</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.813290e-02</td>\n",
       "      <td>0.901867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>company_codes_lineage</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.418755e-03</td>\n",
       "      <td>0.995581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>snippet</th>\n",
       "      <td>0.988084</td>\n",
       "      <td>9.037721e-01</td>\n",
       "      <td>0.106997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>publication_date</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.116277e-01</td>\n",
       "      <td>0.788372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>market_index_codes</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.304125e-03</td>\n",
       "      <td>0.993696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>credit</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.578687e-04</td>\n",
       "      <td>0.999042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>currency_codes</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.358825e-04</td>\n",
       "      <td>0.999864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region_of_origin</th>\n",
       "      <td>0.999788</td>\n",
       "      <td>1.029631e-04</td>\n",
       "      <td>0.999897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ingestion_datetime</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.295663e-01</td>\n",
       "      <td>0.370434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>modification_date</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.869020e-01</td>\n",
       "      <td>0.113098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source_name</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.196767e-03</td>\n",
       "      <td>0.997803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>language_code</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.147065e-07</td>\n",
       "      <td>0.999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region_codes</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.923275e-02</td>\n",
       "      <td>0.970767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>company_codes_association</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.147065e-07</td>\n",
       "      <td>0.999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person_codes</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.579899e-02</td>\n",
       "      <td>0.914201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>byline</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.056430e-02</td>\n",
       "      <td>0.969436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>company_codes_relevance</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.585252e-01</td>\n",
       "      <td>0.741475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source_code</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.105149e-03</td>\n",
       "      <td>0.997895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>an</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_count</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.242949e-03</td>\n",
       "      <td>0.992757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>company_codes</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.621789e-01</td>\n",
       "      <td>0.637821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>industry_codes</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.867213e-02</td>\n",
       "      <td>0.931328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.835670e-01</td>\n",
       "      <td>0.216433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>publication_datetime</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.116277e-01</td>\n",
       "      <td>0.788372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>publisher_name</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.339714e-04</td>\n",
       "      <td>0.999266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>action</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.029413e-06</td>\n",
       "      <td>0.999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>document_type</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.147065e-07</td>\n",
       "      <td>0.999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>section</th>\n",
       "      <td>0.448260</td>\n",
       "      <td>6.175186e-03</td>\n",
       "      <td>0.997231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dateline</th>\n",
       "      <td>0.013851</td>\n",
       "      <td>1.921519e-01</td>\n",
       "      <td>0.997338</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Completeness    Uniqueness  Duplicates\n",
       "copyright                      1.000000  7.014934e-03    0.992985\n",
       "subject_codes                  1.000000  1.732466e-01    0.826753\n",
       "art                            1.000000  1.040685e-02    0.989593\n",
       "modification_datetime          1.000000  6.468182e-01    0.353182\n",
       "body                           0.975772  8.207384e-01    0.199146\n",
       "company_codes_occur            1.000000  1.813707e-01    0.818629\n",
       "company_codes_about            1.000000  9.813290e-02    0.901867\n",
       "company_codes_lineage          1.000000  4.418755e-03    0.995581\n",
       "snippet                        0.988084  9.037721e-01    0.106997\n",
       "publication_date               1.000000  2.116277e-01    0.788372\n",
       "market_index_codes             1.000000  6.304125e-03    0.993696\n",
       "credit                         1.000000  9.578687e-04    0.999042\n",
       "currency_codes                 1.000000  1.358825e-04    0.999864\n",
       "region_of_origin               0.999788  1.029631e-04    0.999897\n",
       "ingestion_datetime             1.000000  6.295663e-01    0.370434\n",
       "modification_date              1.000000  8.869020e-01    0.113098\n",
       "source_name                    1.000000  2.196767e-03    0.997803\n",
       "language_code                  1.000000  5.147065e-07    0.999999\n",
       "region_codes                   1.000000  2.923275e-02    0.970767\n",
       "company_codes_association      1.000000  5.147065e-07    0.999999\n",
       "person_codes                   1.000000  8.579899e-02    0.914201\n",
       "byline                         1.000000  3.056430e-02    0.969436\n",
       "company_codes_relevance        1.000000  2.585252e-01    0.741475\n",
       "source_code                    1.000000  2.105149e-03    0.997895\n",
       "an                             1.000000  1.000000e+00    0.000000\n",
       "word_count                     1.000000  7.242949e-03    0.992757\n",
       "company_codes                  1.000000  3.621789e-01    0.637821\n",
       "industry_codes                 1.000000  6.867213e-02    0.931328\n",
       "title                          1.000000  7.835670e-01    0.216433\n",
       "publication_datetime           1.000000  2.116277e-01    0.788372\n",
       "publisher_name                 1.000000  7.339714e-04    0.999266\n",
       "action                         1.000000  1.029413e-06    0.999999\n",
       "document_type                  1.000000  5.147065e-07    0.999999\n",
       "section                        0.448260  6.175186e-03    0.997231\n",
       "dateline                       0.013851  1.921519e-01    0.997338"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prof.drop('Row', inplace = True)\n",
    "prof"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><b>Put all the invalid company codes into a dataframe</b><h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_df = pd.read_csv(\"../data/working/invalidcompanycodes.csv\", index_col = [0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><b>Creating a valid company code dictionary</b></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_company_codes = invalid_df.code.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_dict.rename(columns = {' description': 'description'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_companies = pd.DataFrame()\n",
    "valid_codes = np.array([])\n",
    "valid_desc = np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in code_dict.itertuples():\n",
    "    if row.code in unique_company_codes:\n",
    "        valid_codes = np.append(valid_codes, row.code)\n",
    "        valid_desc = np.append(valid_desc, row.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_companies['Code'] = valid_codes\n",
    "valid_companies['Description'] = valid_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_companies.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_companies.to_csv(\"../data/working/validcompaniesdictionary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_valid_df = pd.read_csv(\"../data/working/validcompaniesdictionary.csv\", index_col = [0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Code</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AA</td>\n",
       "      <td>AA PLC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAAADJ</td>\n",
       "      <td>Emperial Americas, Inc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAAAIY</td>\n",
       "      <td>American Academy of Allergy, Asthma and Immuno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AAABBB</td>\n",
       "      <td>Bird Studies Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AAACK</td>\n",
       "      <td>Aesculap AG &amp; Co. KG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Code                                        Description\n",
       "0      AA                                             AA PLC\n",
       "2  AAAADJ                            Emperial Americas, Inc.\n",
       "3  AAAAIY  American Academy of Allergy, Asthma and Immuno...\n",
       "5  AAABBB                                Bird Studies Canada\n",
       "6   AAACK                               Aesculap AG & Co. KG"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_valid_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><b>Conclusions</b></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Validity: Defined here as codes that are not in the data dictionary</h4>\n",
    "<p>Looking at the validity of the company columns</p>\n",
    "<ol>\n",
    "    <li>Company_codes had just under 87% valid codes in its column. That means that of all the unique codes in this\n",
    "        column, 13% or so were not in the data dictionary</li>\n",
    "    <li>Company_codes_occur was 89% valid for all unique codes in its column</li>\n",
    "    <li>Both company_codes_about and company_codes_lineage were 99% valid</li>\n",
    "    <li>Company_codes_relevance was 86% valid</li>\n",
    "</ol>\n",
    "\n",
    "<p>There were 73,688 unique company codes in this dataset. Of those 73,688, 9683 were considered invalid since they did not appear in the data dictionary. This left 64,005 valid companies. Each company's code and name are provided in the validcompaniesdictionary.csv. A list of the invalid company codes are also available in the invalidcompanycodes.csv</p>\n",
    "\n",
    "<p>There were 161,321 rows in the DNA dataset that had at least one invalid company code in its company_codes column</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Completeness, Uniqueness, and Duplicates</h4>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Completeness</th>\n",
       "      <th>Uniqueness</th>\n",
       "      <th>Duplicates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>copyright</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.014934e-03</td>\n",
       "      <td>0.992985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject_codes</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.732466e-01</td>\n",
       "      <td>0.826753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>art</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.040685e-02</td>\n",
       "      <td>0.989593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>modification_datetime</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.468182e-01</td>\n",
       "      <td>0.353182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>body</th>\n",
       "      <td>0.975772</td>\n",
       "      <td>8.207384e-01</td>\n",
       "      <td>0.199146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>company_codes_occur</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.813707e-01</td>\n",
       "      <td>0.818629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>company_codes_about</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.813290e-02</td>\n",
       "      <td>0.901867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>company_codes_lineage</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.418755e-03</td>\n",
       "      <td>0.995581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>snippet</th>\n",
       "      <td>0.988084</td>\n",
       "      <td>9.037721e-01</td>\n",
       "      <td>0.106997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>publication_date</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.116277e-01</td>\n",
       "      <td>0.788372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>market_index_codes</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.304125e-03</td>\n",
       "      <td>0.993696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>credit</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.578687e-04</td>\n",
       "      <td>0.999042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>currency_codes</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.358825e-04</td>\n",
       "      <td>0.999864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region_of_origin</th>\n",
       "      <td>0.999788</td>\n",
       "      <td>1.029631e-04</td>\n",
       "      <td>0.999897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ingestion_datetime</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.295663e-01</td>\n",
       "      <td>0.370434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>modification_date</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.869020e-01</td>\n",
       "      <td>0.113098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source_name</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.196767e-03</td>\n",
       "      <td>0.997803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>language_code</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.147065e-07</td>\n",
       "      <td>0.999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region_codes</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.923275e-02</td>\n",
       "      <td>0.970767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>company_codes_association</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.147065e-07</td>\n",
       "      <td>0.999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person_codes</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.579899e-02</td>\n",
       "      <td>0.914201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>byline</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.056430e-02</td>\n",
       "      <td>0.969436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>company_codes_relevance</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.585252e-01</td>\n",
       "      <td>0.741475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source_code</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.105149e-03</td>\n",
       "      <td>0.997895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>an</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_count</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.242949e-03</td>\n",
       "      <td>0.992757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>company_codes</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.621789e-01</td>\n",
       "      <td>0.637821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>industry_codes</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.867213e-02</td>\n",
       "      <td>0.931328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.835670e-01</td>\n",
       "      <td>0.216433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>publication_datetime</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.116277e-01</td>\n",
       "      <td>0.788372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>publisher_name</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.339714e-04</td>\n",
       "      <td>0.999266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>action</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.029413e-06</td>\n",
       "      <td>0.999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>document_type</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.147065e-07</td>\n",
       "      <td>0.999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>section</th>\n",
       "      <td>0.448260</td>\n",
       "      <td>6.175186e-03</td>\n",
       "      <td>0.997231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dateline</th>\n",
       "      <td>0.013851</td>\n",
       "      <td>1.921519e-01</td>\n",
       "      <td>0.997338</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Completeness    Uniqueness  Duplicates\n",
       "copyright                      1.000000  7.014934e-03    0.992985\n",
       "subject_codes                  1.000000  1.732466e-01    0.826753\n",
       "art                            1.000000  1.040685e-02    0.989593\n",
       "modification_datetime          1.000000  6.468182e-01    0.353182\n",
       "body                           0.975772  8.207384e-01    0.199146\n",
       "company_codes_occur            1.000000  1.813707e-01    0.818629\n",
       "company_codes_about            1.000000  9.813290e-02    0.901867\n",
       "company_codes_lineage          1.000000  4.418755e-03    0.995581\n",
       "snippet                        0.988084  9.037721e-01    0.106997\n",
       "publication_date               1.000000  2.116277e-01    0.788372\n",
       "market_index_codes             1.000000  6.304125e-03    0.993696\n",
       "credit                         1.000000  9.578687e-04    0.999042\n",
       "currency_codes                 1.000000  1.358825e-04    0.999864\n",
       "region_of_origin               0.999788  1.029631e-04    0.999897\n",
       "ingestion_datetime             1.000000  6.295663e-01    0.370434\n",
       "modification_date              1.000000  8.869020e-01    0.113098\n",
       "source_name                    1.000000  2.196767e-03    0.997803\n",
       "language_code                  1.000000  5.147065e-07    0.999999\n",
       "region_codes                   1.000000  2.923275e-02    0.970767\n",
       "company_codes_association      1.000000  5.147065e-07    0.999999\n",
       "person_codes                   1.000000  8.579899e-02    0.914201\n",
       "byline                         1.000000  3.056430e-02    0.969436\n",
       "company_codes_relevance        1.000000  2.585252e-01    0.741475\n",
       "source_code                    1.000000  2.105149e-03    0.997895\n",
       "an                             1.000000  1.000000e+00    0.000000\n",
       "word_count                     1.000000  7.242949e-03    0.992757\n",
       "company_codes                  1.000000  3.621789e-01    0.637821\n",
       "industry_codes                 1.000000  6.867213e-02    0.931328\n",
       "title                          1.000000  7.835670e-01    0.216433\n",
       "publication_datetime           1.000000  2.116277e-01    0.788372\n",
       "publisher_name                 1.000000  7.339714e-04    0.999266\n",
       "action                         1.000000  1.029413e-06    0.999999\n",
       "document_type                  1.000000  5.147065e-07    0.999999\n",
       "section                        0.448260  6.175186e-03    0.997231\n",
       "dateline                       0.013851  1.921519e-01    0.997338"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Non-duplicates'] = [set(code) for code in df['company_codes'].str.split(\",\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Non-duplicates'] = [list(code) for code in df['Non-duplicates']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Non-duplicates'] = [','.join(code) for code in df['Non-duplicates']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Non-duplicates'] = df['Non-duplicates'].str[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_codes</th>\n",
       "      <th>Non-duplicates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>,toamsi,toamsi,tosmsc,tosmsc,tshba,tshba,tshba,</td>\n",
       "      <td>tshba,toamsi,tosmsc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>,irevs,irevs,irevs,</td>\n",
       "      <td>irevs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>,euruno,</td>\n",
       "      <td>euruno</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>,retrac,nyse,nyse,retrac,retrac,seexc,</td>\n",
       "      <td>nyse,retrac,seexc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>,brstmy,brstmy,brstmy,</td>\n",
       "      <td>brstmy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1942850</th>\n",
       "      <td>,egalcu,egalcu,egalcu,seexc,</td>\n",
       "      <td>seexc,egalcu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1942851</th>\n",
       "      <td>,endoph,schplo,endoph,endoph,jnsspi,jnsspi,jon...</td>\n",
       "      <td>schplo,endoph,jnsspi,seexc,jonjon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1942852</th>\n",
       "      <td>,amchso,</td>\n",
       "      <td>amchso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1942853</th>\n",
       "      <td>,grnlft,kalamc,stry,stry,stry,</td>\n",
       "      <td>grnlft,stry,kalamc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1942854</th>\n",
       "      <td>,zogeni,ardgm,cowhrp,zogeni,zogeni,endoph,</td>\n",
       "      <td>zogeni,endoph,cowhrp,ardgm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1942855 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             company_codes  \\\n",
       "0          ,toamsi,toamsi,tosmsc,tosmsc,tshba,tshba,tshba,   \n",
       "1                                      ,irevs,irevs,irevs,   \n",
       "2                                                 ,euruno,   \n",
       "3                   ,retrac,nyse,nyse,retrac,retrac,seexc,   \n",
       "4                                   ,brstmy,brstmy,brstmy,   \n",
       "...                                                    ...   \n",
       "1942850                       ,egalcu,egalcu,egalcu,seexc,   \n",
       "1942851  ,endoph,schplo,endoph,endoph,jnsspi,jnsspi,jon...   \n",
       "1942852                                           ,amchso,   \n",
       "1942853                     ,grnlft,kalamc,stry,stry,stry,   \n",
       "1942854         ,zogeni,ardgm,cowhrp,zogeni,zogeni,endoph,   \n",
       "\n",
       "                            Non-duplicates  \n",
       "0                      tshba,toamsi,tosmsc  \n",
       "1                                    irevs  \n",
       "2                                   euruno  \n",
       "3                        nyse,retrac,seexc  \n",
       "4                                   brstmy  \n",
       "...                                    ...  \n",
       "1942850                       seexc,egalcu  \n",
       "1942851  schplo,endoph,jnsspi,seexc,jonjon  \n",
       "1942852                             amchso  \n",
       "1942853                 grnlft,stry,kalamc  \n",
       "1942854         zogeni,endoph,cowhrp,ardgm  \n",
       "\n",
       "[1942855 rows x 2 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['company_codes', 'Non-duplicates']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To conclude, we found that the DNA data set includes 35 different variables with 1942855 entries. 4.5% of those entries were missing an actual value. Additionally, we tested seven variables for validity. The validation criteria depended uniquely on the variable. Overall, we found __ % of the entire data set to pass all of our validity checks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IAN's code from thursday morning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[['company_codes', 'Non-duplicates']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_list = []\n",
    "for code in x['company_codes'].str.split(\",\"):\n",
    "    for code2 in code:\n",
    "        my_list.append(code2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_freq = pd.DataFrame()\n",
    "company_code = np.array([])\n",
    "company_count = np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for company, count in Counter(my_list).items():\n",
    "    company_code = np.append(company_code, company)\n",
    "    company_count = np.append(company_count, count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_freq['Code'] = company_code\n",
    "company_freq['Count'] = company_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_freq = company_freq.sort_values(\"Count\", ascending = False).iloc[1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_freq.set_index(\"Code\", inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "company_freq.Count.head(15).plot(kind = 'bar')\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Top 15 Most Mentioned Companines\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Made a csv of all companies with their frequency counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_freq.to_csv(\"../data/working/companyfrequency.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_freq.reset_index(inplace = True)\n",
    "# Made a csv of all companies with their frequency counts and \n",
    "# corresponding company names(invalid companies will have NaN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = np.array([])\n",
    "val = pd.read_csv(\"../data/working/validcompaniesdictionary.csv\", index_col = [0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_freq['Code'] = company_freq['Code'].str.upper()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging the valid company codes df with the company_freq df. This will match each company with their name, unless invalid\n",
    "merged_df = pd.merge(val, company_freq, left_on = \"Code\", right_on = \"Code\", how = \"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv(\"../data/working/companyfrequencyandname.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.read_csv(\"../data/working/companyfrequencyandname.csv\", index_col = [0])\n",
    "final.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final[final.Code == 'PFIZ']\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
